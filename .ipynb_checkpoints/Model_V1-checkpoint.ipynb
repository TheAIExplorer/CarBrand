{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fafbde8-d270-4d36-8bf8-44b6a68a8ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b48f7529-c77e-43a6-8d7b-094953f59f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the data directory\n",
    "data_dir = r'C:\\Users\\haris\\AI\\ML\\Projects\\Data\\Cars Dataset'\n",
    "\n",
    "# Define the image size and batch size\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Function to get images and labels\n",
    "def load_and_preprocess_data(subdir_name):\n",
    "    # Load and preprocess the training data\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through each subdirectory (class)\n",
    "    class_folders = os.listdir(os.path.join(data_dir, subdir_name))\n",
    "    num_classes = len(class_folders)\n",
    "\n",
    "    for class_index, class_folder in enumerate(class_folders):\n",
    "        class_path = os.path.join(data_dir, subdir_name, class_folder)\n",
    "        for image_file in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            img = load_img(image_path, target_size = img_size)\n",
    "            img_array = img_to_array(img)\n",
    "            img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "            images.append(img_array)\n",
    "            labels.append(class_index)\n",
    "    images = np.array(images)\n",
    "    labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "    return images, labels, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8afc5656-5bbc-4322-9ef2-8ae4e9ce3bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3352, 224, 224, 3) (3352, 7) 7\n"
     ]
    }
   ],
   "source": [
    "images, labels, num_classes = load_and_preprocess_data('train')\n",
    "print(images.shape, labels.shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af6740ef-0a13-4da2-be2c-5e32a1e51cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 12s 33ms/step - loss: 0.7845 - accuracy: 0.7396\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.3215 - accuracy: 0.8908\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.1903 - accuracy: 0.9415\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.1173 - accuracy: 0.9651\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.0741 - accuracy: 0.9785\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.0470 - accuracy: 0.9881\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.0214 - accuracy: 0.9961\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 4s 35ms/step - loss: 0.0124 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.0043 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Load the MobileNetV2 pre-trained model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add custom classification layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    images,\n",
    "    labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=10,  # You can adjust the number of epochs as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad964255-3502-4e62-92ce-5e08d1d98ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 16s 601ms/step - loss: 0.3297 - accuracy: 0.9114\n",
      "Test Loss: 0.3297272324562073\n",
      "Test Accuracy: 0.9114391207695007\n"
     ]
    }
   ],
   "source": [
    "# Testing the trained model on the test dataset\n",
    "test_images, test_labels, num_classes = load_and_preprocess_data('test')\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425fee7-0a9e-45ae-a3d4-c5913fae97ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
